{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1aE__9am9yZgteB7cXqGUr2Q2GKSd37Ox",
      "authorship_tag": "ABX9TyPmiUHX2nLkh1+ohhE7xQQ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lenazlobina/Project-2/blob/main/%D0%97%D0%BB%D0%BE%D0%B1%D0%B8%D0%BD%D0%B0_%D0%95%D0%BB%D0%B5%D0%BD%D0%B0__%D0%9F%D1%80%D0%BE%D0%B5%D0%BA%D1%82_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Статистический метод\n",
        "Данный метод опирается на подсчет разницы между частотами общих слов из каждой сравниваемой пары корпусов и суммирование квадратов этих разниц. Полученная сумма для каждой пары называется индексом схожести (similarity score).\n",
        "Тексты с меньшим индексом схожести являются более близкими по количественно-словарному составу."
      ],
      "metadata": {
        "id": "1fXqtvR7BBUp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zsIkO2hdecR",
        "outputId": "dae42c3d-985f-48d9-8de4-f1f7ea934179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# указываем путь к файлам с корпусами текстов (автор = text1, псевдоним = text2, коллега = text3)\n",
        "file_path1 = '/content/drive/My Drive/P2TF/articles_1.txt'\n",
        "with open(file_path1, 'r', encoding='utf-8') as f: text1 = f.read()\n"
      ],
      "metadata": {
        "id": "i8Hz1VNDWsUf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYeQBi4lWzKr",
        "outputId": "1d004dd4-237f-49f8-b80b-af885dda873d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300469"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# приводим остальные два корпуса к длине первого корпуса, чтобы разница в количестве общих слов не слишком влияла на вычисляемый нами индекс схожести (similarity_score)\n",
        "file_path2 = '/content/drive/My Drive/P2TF/articles_2.txt'\n",
        "with open(file_path2, 'r', encoding='utf-8') as f: text2 = f.read()[:300469]\n",
        "\n",
        "file_path3 = '/content/drive/My Drive/P2TF/articles_3.txt'\n",
        "with open(file_path3, 'r', encoding='utf-8') as f: text3 = f.read()[:300469]"
      ],
      "metadata": {
        "id": "174ziwujW3cq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# предобрабатываем и токенизируем корпуса, удаляем стоп-слова, прописываем функции для вычисления индекса схожести между корпусами попарно\n",
        "# попробуем несколько вариантов предобработки, чтобы выяснить наиболее эффективный для данной задачи\n",
        "# Предобработка 1 - без стоп-слов\n",
        "def clean_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    words = [word.lower() for word in tokens if word.isalpha()]\n",
        "    filtered_words = [word for word in words if word not in stopwords.words('russian')]\n",
        "    return filtered_words\n",
        "\n",
        "def calculate_similarity_true(text1, text2):\n",
        "    clean_text1 = clean_text(text1)\n",
        "    clean_text2 = clean_text(text2)\n",
        "\n",
        "    counter1 = Counter(clean_text1)\n",
        "    counter2 = Counter(clean_text2)\n",
        "\n",
        "    common_words_true = set(counter1.keys()) & set(counter2.keys())\n",
        "\n",
        "    similarity_true = sum((counter1[word] - counter2[word]) ** 2 for word in common_words_true)\n",
        "\n",
        "    return similarity_true\n",
        "\n",
        "def calculate_similarity_false(text2, text3):\n",
        "    clean_text2 = clean_text(text2)\n",
        "    clean_text3 = clean_text(text3)\n",
        "\n",
        "    counter2 = Counter(clean_text2)\n",
        "    counter3 = Counter(clean_text3)\n",
        "\n",
        "    common_words_false = set(counter2.keys()) & set(counter3.keys())\n",
        "\n",
        "    similarity_false = sum((counter2[word] - counter3[word]) ** 2 for word in common_words_false)\n",
        "\n",
        "    return similarity_false"
      ],
      "metadata": {
        "id": "KuXsZBtHeyuj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clean_text(text1)[:20])# на всякий случай проверяем, как выглядел предобработанный корпус - стоп-слова удалены"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEUIGtnXIxrL",
        "outputId": "80639e10-0979-442a-eb86-f10398a58d49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['году', 'петербургский', 'международный', 'экономический', 'форум', 'пмэф', 'отмечает', 'юбилей', 'мероприятие', 'проводится', 'преддверии', 'форума', 'октагон', 'задал', 'вопросы', 'ключевым', 'финансовым', 'темам', 'последних', 'недель']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# вычисляем индекс схожести\n",
        "similarity_score_true = calculate_similarity_true(text1, text2)\n",
        "print(\"Индекс схожести текстов из корпуса автора и корпуса под псевдонимом:\", similarity_score_true)\n",
        "\n",
        "similarity_score_false = calculate_similarity_false(text2, text3)\n",
        "print(\"Индекс схожести текстов из корпуса под псевдонимом и корпуса коллеги:\", similarity_score_false)\n",
        "\n",
        "# индекс схожести корпуса под псевдонимом с корпусом автора в 1,37 раза лучше, чем корпуса под псевдонимом с корпусом коллеги"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SEn6RiVe5uF",
        "outputId": "08100233-8902-489c-bd99-f83bdc155c6e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Индекс схожести текстов из корпуса автора и корпуса под псевдонимом: 128990\n",
            "Индекс схожести текстов из корпуса под псевдонимом и корпуса коллеги: 177118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предобработка 2 - то же, что и в Предобработке 1, но не будем удалять стоп-слова, т.к. служебные части речи могут указывать на авторский стиль\n",
        "def clean_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    words = [word.lower() for word in tokens if word.isalpha()]\n",
        "    #filtered_words = [word for word in words if word not in stopwords.words('russian')]\n",
        "    return words\n",
        "\n",
        "def calculate_similarity_true(text1, text2):\n",
        "    clean_text1 = clean_text(text1)\n",
        "    clean_text2 = clean_text(text2)\n",
        "\n",
        "    counter1 = Counter(clean_text1)\n",
        "    counter2 = Counter(clean_text2)\n",
        "\n",
        "    common_words_true = set(counter1.keys()) & set(counter2.keys())\n",
        "\n",
        "    similarity_true = sum((counter1[word] - counter2[word]) ** 2 for word in common_words_true)\n",
        "\n",
        "    return similarity_true\n",
        "\n",
        "def calculate_similarity_false(text2, text3):\n",
        "    clean_text2 = clean_text(text2)\n",
        "    clean_text3 = clean_text(text3)\n",
        "\n",
        "    counter2 = Counter(clean_text2)\n",
        "    counter3 = Counter(clean_text3)\n",
        "\n",
        "    common_words_false = set(counter2.keys()) & set(counter3.keys())\n",
        "\n",
        "    similarity_false = sum((counter2[word] - counter3[word]) ** 2 for word in common_words_false)\n",
        "\n",
        "    return similarity_false"
      ],
      "metadata": {
        "id": "KPMm3v0b7I-r"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clean_text(text1)[:20]) # на всякий случай проверяем, как выглядел предобработанный корпус - стоп-слова в нем не удалялись"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uit2BuXEG4-c",
        "outputId": "16e95443-6d40-4288-c092-2dd0d52fe957"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['в', 'этом', 'году', 'петербургский', 'международный', 'экономический', 'форум', 'пмэф', 'отмечает', 'юбилей', 'мероприятие', 'проводится', 'в', 'раз', 'в', 'преддверии', 'форума', 'октагон', 'задал', 'вопросы']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# вычисляем индексы схожести\n",
        "similarity_score_true = calculate_similarity_true(text1, text2)\n",
        "print(\"Индекс схожести текстов из корпуса автора и корпуса под псевдонимом:\", similarity_score_true)\n",
        "\n",
        "similarity_score_false = calculate_similarity_false(text2, text3)\n",
        "print(\"Индекс схожести текстов из корпуса под псевдонимом и корпуса коллеги:\", similarity_score_false)\n",
        "# индекс схожести корпуса автора и корпуса под псевдонимом примерно в 1.48 раз лучше, чем индекс схожести корпуса под пресвдонимои и корпуса коллеги\n",
        "# Получается, токенизация с оставлением стоп-слов сработала чуть лучше, чем токенизация без стоп-слов"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGnrputg7kU7",
        "outputId": "40aadbe2-8892-4ea7-8590-d11b68e838c7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Индекс схожести текстов из корпуса автора и корпуса под псевдонимом: 421438\n",
            "Индекс схожести текстов из корпуса под псевдонимом и корпуса коллеги: 570958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymystem3 import Mystem\n",
        "mystem = Mystem()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnKlqq-7_-ZO",
        "outputId": "a072f47a-6626-4599-8f67-b6fe438e54b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предобработка 3 - добавим лемматизацию, но не будем удалять стоп-слова, т.к. служебные части речи могут указывать на авторский стиль\n",
        "\n",
        "def clean_text(text):\n",
        "    text_lemmatized = mystem.lemmatize(text)\n",
        "    text_without_punkt_lem = [word.lower() for word in text_lemmatized if word.isalpha()]\n",
        "    text_list_without_punkt_lem = ' '.join(text_without_punkt_lem)\n",
        "    tokens = word_tokenize(text_list_without_punkt_lem)\n",
        "    return tokens\n",
        "\n",
        "def calculate_similarity_true(text1, text2):\n",
        "    clean_text1 = clean_text(text1)\n",
        "    clean_text2 = clean_text(text2)\n",
        "\n",
        "    counter1 = Counter(clean_text1)\n",
        "    counter2 = Counter(clean_text2)\n",
        "\n",
        "    common_words_true = set(counter1.keys()) & set(counter2.keys())\n",
        "\n",
        "    similarity_true = sum((counter1[word] - counter2[word]) ** 2 for word in common_words_true)\n",
        "\n",
        "    return similarity_true\n",
        "\n",
        "def calculate_similarity_false(text2, text3):\n",
        "    clean_text2 = clean_text(text2)\n",
        "    clean_text3 = clean_text(text3)\n",
        "\n",
        "    counter2 = Counter(clean_text2)\n",
        "    counter3 = Counter(clean_text3)\n",
        "\n",
        "    common_words_false = set(counter2.keys()) & set(counter3.keys())\n",
        "\n",
        "    similarity_false = sum((counter2[word] - counter3[word]) ** 2 for word in common_words_false)\n",
        "\n",
        "    return similarity_false"
      ],
      "metadata": {
        "id": "j1UObhYo32S0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clean_text(text1)[:20]) # на всякий случай проверяем, как выглядел предобработанный корпус - лемматизация прошла успешно, стоп-слова не удалялись"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmkgtnorGGuD",
        "outputId": "c30380ff-be9f-41cb-c8f9-b9e5ab4c3d4d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['в', 'этот', 'год', 'петербургский', 'международный', 'экономический', 'форум', 'пмэф', 'отмечать', 'юбилей', 'мероприятие', 'проводиться', 'в', 'й', 'раз', 'в', 'преддверие', 'форум', 'октагон', 'задавать']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# вычисляем индексы схожести\n",
        "similarity_score_true = calculate_similarity_true(text1, text2)\n",
        "print(\"Индекс схожести текстов из корпуса автора и корпуса под псевдонимом:\", similarity_score_true)\n",
        "\n",
        "similarity_score_false = calculate_similarity_false(text2, text3)\n",
        "print(\"Индекс схожести текстов из корпуса под псевдонимом и корпуса коллеги:\", similarity_score_false)\n",
        "\n",
        "# индекс схожести корпуса автора и корпуса под псевдонимом в 1.35 раз лучше, чем индекс схожести корпуса под псевдонимом и корпуса коллеги\n",
        "# тем не менее, это самый маленький по схожести индекс из всех полученных"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5mGbuIfSUaj",
        "outputId": "16821d8d-5720-46f0-bf20-a6b4e963a846"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Индекс схожести текстов из корпуса автора и корпуса под псевдонимом: 421438\n",
            "Индекс схожести текстов из корпуса под псевдонимом и корпуса коллеги: 570958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предобработка 4 - посмотрим, как повлияет на индекс схожести удаление стоп-слов из лемматизированных и токенизированных корпусов\n",
        "\n",
        "def clean_text(text):\n",
        "    text_lemmatized = mystem.lemmatize(text)\n",
        "    text_without_punkt_lem = [word.lower() for word in text_lemmatized if word.isalpha()]\n",
        "    text_list_without_punkt_lem = ' '.join(text_without_punkt_lem)\n",
        "    tokens = word_tokenize(text_list_without_punkt_lem)\n",
        "    filtered_words = [word for word in tokens if word not in stopwords.words('russian')]\n",
        "    return filtered_words\n",
        "\n",
        "def calculate_similarity_true(text1, text2):\n",
        "    clean_text1 = clean_text(text1)\n",
        "    clean_text2 = clean_text(text2)\n",
        "\n",
        "    counter1 = Counter(clean_text1)\n",
        "    counter2 = Counter(clean_text2)\n",
        "\n",
        "    common_words_true = set(counter1.keys()) & set(counter2.keys())\n",
        "\n",
        "    similarity_true = sum((counter1[word] - counter2[word]) ** 2 for word in common_words_true)\n",
        "\n",
        "    return similarity_true\n",
        "\n",
        "def calculate_similarity_false(text2, text3):\n",
        "    clean_text2 = clean_text(text2)\n",
        "    clean_text3 = clean_text(text3)\n",
        "\n",
        "    counter2 = Counter(clean_text2)\n",
        "    counter3 = Counter(clean_text3)\n",
        "\n",
        "    common_words_false = set(counter2.keys()) & set(counter3.keys())\n",
        "\n",
        "    similarity_false = sum((counter2[word] - counter3[word]) ** 2 for word in common_words_false)\n",
        "\n",
        "    return similarity_false"
      ],
      "metadata": {
        "id": "QwjqcKGdTmdu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clean_text(text1)[:20]) # на всякий случай проверяем, как выглядел предобработанный корпус - лемматизация прошла успешно, стоп-слова удалены"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZS8JHHxFvWY",
        "outputId": "ca4e033b-5e0f-40a5-bc2a-2f52fbed7352"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['год', 'петербургский', 'международный', 'экономический', 'форум', 'пмэф', 'отмечать', 'юбилей', 'мероприятие', 'проводиться', 'й', 'преддверие', 'форум', 'октагон', 'задавать', 'вопрос', 'ключевой', 'финансовый', 'тема', 'последний']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# вычисляем индексы схожести\n",
        "similarity_score_true = calculate_similarity_true(text1, text2)\n",
        "print(\"Индекс схожести текстов из корпуса автора и корпуса под псевдонимом:\", similarity_score_true)\n",
        "\n",
        "similarity_score_false = calculate_similarity_false(text2, text3)\n",
        "print(\"Индекс схожести текстов из корпуса под псевдонимом и корпуса коллеги:\", similarity_score_false)\n",
        "\n",
        "# индекс схожести корпуса автора и корпуса под псевдонимом в 1.52 раза лучше, чем индекс схожести корпуса под псевдонимом и корпуса коллеги\n",
        "# это наиболее удачный результат из всех четырех"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_g9IfVCUVWc",
        "outputId": "b017feca-3384-4982-bb9b-0e455c09d0b7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Индекс схожести текстов из корпуса автора и корпуса под псевдонимом: 269341\n",
            "Индекс схожести текстов из корпуса под псевдонимом и корпуса коллеги: 409983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:** Статистическая мера сработала, во всех случаях индекс схожести корпуса под псевдонимом и корпуса автора был меньше(т.е. лучше) индекса схожести корпуса под псевдонимом и корпуса коллеги. Разница в лучшем (1,52) и худшем (1,35) соотношении индексов схожести совсем небольшая, поэтому добавление лемматизации и удаление стоп-слов в моем случае не оказало существенного влияния на результат.\n",
        "В любом случае, успешный результат использования данного метода говорит, скорее, о лексическом сходстве между вокабулярами корпусов, чем о принадлежности их одному автору."
      ],
      "metadata": {
        "id": "LCuS9rQ_GRme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Векторное сходство\n",
        "Этот способ заключается в применении Tf-Idf векторизатора и вычислении косинусного сходства между корпусами.\n"
      ],
      "metadata": {
        "id": "8drw8sJAIGNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "wipCfWWXKeAt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Для работы с корпусами полной длины у моего компьютера не было достаточно памяти, поэтому я решила сократить их объем до 200 тысяч знаков\n",
        "file_path1 = '/content/drive/My Drive/P2TF/articles_1.txt'\n",
        "with open(file_path1, 'r', encoding='utf-8') as f: text1_short = f.read()[:200000]\n",
        "\n",
        "file_path2 = '/content/drive/My Drive/P2TF/articles_2.txt'\n",
        "with open(file_path2, 'r', encoding='utf-8') as f: text2_short = f.read()[:200000]\n",
        "\n",
        "file_path3 = '/content/drive/My Drive/P2TF/articles_3.txt'\n",
        "with open(file_path3, 'r', encoding='utf-8') as f: text3_short = f.read()[:200000]"
      ],
      "metadata": {
        "id": "MPEbfe9PefZV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сначала попробуем подать в код тексты без предобработки\n",
        "corpus = [\n",
        "    text1_short,\n",
        "    text2_short,\n",
        "    text3_short\n",
        "]"
      ],
      "metadata": {
        "id": "JR5k125yl4eU"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# проверим, как выгладит корпус\n",
        "print((corpus[0][:100]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9Q1DNqhSm4S",
        "outputId": "aff6347b-aa7e-4768-ae55-d0668703f3c9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "В этом году Петербургский международный экономический форум (ПМЭФ) отмечает юбилей – мероприятие про\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# создаем объект TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "2WN3o8AqUcUz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# преобразуем тексты в матрицу Tf-Idf признаков\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "aWvcg-aJmlYg"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# вычисляем сходство между матрицами признаков\n",
        "similarity_matrix = cosine_similarity(tfidf_matrix)"
      ],
      "metadata": {
        "id": "aw0qlhuysaWX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(corpus)):\n",
        "    print(f\"Схожесть текста {i+1} с остальными текстами:\")\n",
        "    for j in range(len(corpus)):\n",
        "        if i != j:\n",
        "            print(f\"Текст {i+1} и текст {j+1}: {similarity_matrix[i][j]}\")\n",
        "# полученное косинусное сходство гоорит о большей схожести корпуса автора с корпусом под псевдонимом (0.90), чем о схожести корпуса псевдонима с корпусом коллеги (0.86)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAp05tnTsibB",
        "outputId": "602b70f2-c9dc-4ea0-f797-c8bc7a68d53a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть текста 1 с остальными текстами:\n",
            "Текст 1 и текст 2: 0.9041297422291208\n",
            "Текст 1 и текст 3: 0.8858423553980781\n",
            "Схожесть текста 2 с остальными текстами:\n",
            "Текст 2 и текст 1: 0.9041297422291208\n",
            "Текст 2 и текст 3: 0.8666426469300487\n",
            "Схожесть текста 3 с остальными текстами:\n",
            "Текст 3 и текст 1: 0.8858423553980781\n",
            "Текст 3 и текст 2: 0.8666426469300487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# теперь попробуем предобработать текст перед подачей в векторизатор\n",
        "# токенизируем тексты, приведем все слова к нижнему регистру, удалим небуквенные символы, но не будем пока удалять стоп-слова и лемматизировать корпуса\n",
        "\n",
        "def clean_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    words = [word for word in tokens if word.isalpha()]\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "Xbi5IdAgMWFR"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus1 = [\n",
        "    clean_text(text1_short),\n",
        "    clean_text(text2_short),\n",
        "    clean_text(text3_short)\n",
        "]\n"
      ],
      "metadata": {
        "id": "Mn0-gxdKOkIr"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus1[0][:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k9n2UfJOwjF",
        "outputId": "bea1b96f-19e6-4a28-9d9c-0f27c61d37fd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "в этом году петербургский международный экономический форум пмэф отмечает юбилей мероприятие проводи\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix1 = tfidf_vectorizer.fit_transform(corpus1)"
      ],
      "metadata": {
        "id": "dh_ZOCDNK-Py"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix1 = cosine_similarity(tfidf_matrix1)"
      ],
      "metadata": {
        "id": "rAaLKV0_OMyA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(corpus1)):\n",
        "    print(f\"Схожесть текста {i+1} с остальными текстами:\")\n",
        "    for j in range(len(corpus1)):\n",
        "        if i != j:\n",
        "            print(f\"Текст {i+1} и текст {j+1}: {similarity_matrix1[i][j]}\")\n",
        "# полученные значения очень близки к тем, что были при подаче  текстов без предобработки"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6n1tfSYWHHm",
        "outputId": "04f8f699-bba5-4197-bc47-45a15decbe7b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть текста 1 с остальными текстами:\n",
            "Текст 1 и текст 2: 0.9079671234031804\n",
            "Текст 1 и текст 3: 0.8872161883584108\n",
            "Схожесть текста 2 с остальными текстами:\n",
            "Текст 2 и текст 1: 0.9079671234031804\n",
            "Текст 2 и текст 3: 0.8686910973792725\n",
            "Схожесть текста 3 с остальными текстами:\n",
            "Текст 3 и текст 1: 0.8872161883584108\n",
            "Текст 3 и текст 2: 0.8686910973792725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Следующий вариант предобработки - та, что обычно рекомендуется для данного метода: то же, что и в предыдущем пункте, но также удалим стоп-слова\n",
        "def clean_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    words = [word for word in tokens if word.isalpha()]\n",
        "    filtered_words = [word for word in words if word not in stopwords.words('russian')]\n",
        "    return ' '.join(filtered_words)"
      ],
      "metadata": {
        "id": "heQxCLiUjtQG"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus2 = [\n",
        "    clean_text(text1_short),\n",
        "    clean_text(text2_short),\n",
        "    clean_text(text3_short)\n",
        "]"
      ],
      "metadata": {
        "id": "ORZWtp2qj4BX"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus2[0][:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTGjVNRtj9kW",
        "outputId": "a219a9e3-9fe8-4dd5-e524-da5dd0a8a226"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "году петербургский международный экономический форум пмэф отмечает юбилей мероприятие проводится пре\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix2 = tfidf_vectorizer.fit_transform(corpus2)"
      ],
      "metadata": {
        "id": "GJ1ajKJllYhM"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix2 = cosine_similarity(tfidf_matrix2)"
      ],
      "metadata": {
        "id": "jZQ0jpAwlg5W"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(corpus2)):\n",
        "    print(f\"Схожесть текста {i+1} с остальными текстами:\")\n",
        "    for j in range(len(corpus2)):\n",
        "        if i != j:\n",
        "            print(f\"Текст {i+1} и текст {j+1}: {similarity_matrix2[i][j]}\")\n",
        "# полученные значения снизились в числовом выражении, но остались сопоставимыми и симметричными тем, что были в предыдущих пунктах\n",
        "# еще лучше проявилась разница в косинусном сходстве между автором-псевдонимом(0.66) и коллегой-псевдонимом(0.54), т.е. псевдоним гораздо ближе к автору, что соответствует действительности"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRUeLpankREu",
        "outputId": "318b8514-460e-46b9-ed5c-9bc13546237a"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть текста 1 с остальными текстами:\n",
            "Текст 1 и текст 2: 0.6605525303521329\n",
            "Текст 1 и текст 3: 0.6090660015094606\n",
            "Схожесть текста 2 с остальными текстами:\n",
            "Текст 2 и текст 1: 0.6605525303521329\n",
            "Текст 2 и текст 3: 0.549447971684852\n",
            "Схожесть текста 3 с остальными текстами:\n",
            "Текст 3 и текст 1: 0.6090660015094606\n",
            "Текст 3 и текст 2: 0.549447971684852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Для эксперимента добавим лемматизацию в предобработку и посмотрим на результаты как со стоп-словами, так и без них\n",
        "def clean_text(text):\n",
        "    text_lemmatized = mystem.lemmatize(text)\n",
        "    text_without_punkt_lem = [word.lower() for word in text_lemmatized if word.isalpha()] # and word not in stopwords.words('russian')]\n",
        "    return ' '.join(text_without_punkt_lem)"
      ],
      "metadata": {
        "id": "p_0bnFLtlwQ5"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus3 = [\n",
        "    clean_text(text1_short),\n",
        "    clean_text(text2_short),\n",
        "    clean_text(text3_short)\n",
        "]"
      ],
      "metadata": {
        "id": "OBRzFgPIcF0W"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus3[0][:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpv65pPkcVHy",
        "outputId": "03a4c45f-4113-4292-c7e2-1b1e501bb315"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "в этот год петербургский международный экономический форум пмэф отмечать юбилей мероприятие проводит\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix3 = tfidf_vectorizer.fit_transform(corpus3)"
      ],
      "metadata": {
        "id": "B7bMogcUcjhV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix3 = cosine_similarity(tfidf_matrix3)"
      ],
      "metadata": {
        "id": "6R3O5wPucnrG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(corpus3)):\n",
        "    print(f\"Схожесть текста {i+1} с остальными текстами:\")\n",
        "    for j in range(len(corpus3)):\n",
        "        if i != j:\n",
        "            print(f\"Текст {i+1} и текст {j+1}: {similarity_matrix3[i][j]}\")\n",
        "# Полученные значения сопоставимы и пропорциональны тем, что были получены выше.\n",
        "# Делаем вывод, что лемматизация не оказывает существенного влияния на результаты вычисления косинусного сходства"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeX1M2fPcndm",
        "outputId": "63cced88-e981-4c3d-dc14-d928567a88e9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть текста 1 с остальными текстами:\n",
            "Текст 1 и текст 2: 0.9070809515083691\n",
            "Текст 1 и текст 3: 0.8831019005990008\n",
            "Схожесть текста 2 с остальными текстами:\n",
            "Текст 2 и текст 1: 0.9070809515083691\n",
            "Текст 2 и текст 3: 0.8567370076989871\n",
            "Схожесть текста 3 с остальными текстами:\n",
            "Текст 3 и текст 1: 0.8831019005990008\n",
            "Текст 3 и текст 2: 0.8567370076989871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод**: Векторное сходство сработало успешно, и во всех случаях числовое значение косинусного сходства в паре автор-псевдоним было ближе к 1, чем в паре коллега-псевдоним. Но поскольку все полученные значения были ближе к 1, чем к 0, то в данном случае нельзя говорить о ярко выраженных различиях между корпусами. Маленькая разница в косинусном сходстве между всеми корпусами может быть объяснена тем, что тематически и стилистически корпуса очень близки друг к другу, написаны они также были примерно в одно время.\n",
        "\n",
        "Что касается наиболеее эффективной предобработки, то удаление стоп-слов занижает числовые показатели косинусного сходства, но при этом размеры числовых показателей вполне пропорциональны тем, которые получаются, если не удалять стоп-слова. Лемматизация (как с сохранением, так и с удалением стоп-слов) не оказывает существенного влияния на результаты вычисления косинусного сходства.\n",
        "Рекомендованный во многих источниках способ предобработки перед векторизацией, включающий в себя приведение к нижнему регистру, токенизацию, удаление небуквенных символов и удаление стоп-слов, действительно доказал свою эффективность."
      ],
      "metadata": {
        "id": "jzMdClYyr_Sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Машинное обучение\n"
      ],
      "metadata": {
        "id": "e45MbJlyC5Z7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1  Модель для классификации текстов на два класса (автор или коллега) на основе логистической регрессии."
      ],
      "metadata": {
        "id": "7fRgKRz3VkEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "9u4IenjlDpA_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтобы у модели было больше примеров каждого класса, разобьем каждый текст на три отрезка\n",
        "file_path1 = '/content/drive/My Drive/P2TF/articles_1.txt'\n",
        "with open(file_path1, 'r', encoding='utf-8') as f: text1 = f.read()[:100000]\n",
        "with open(file_path1, 'r', encoding='utf-8') as f: text2 = f.read()[100000:200000]\n",
        "with open(file_path1, 'r', encoding='utf-8') as f: text3 = f.read()[200000:]\n",
        "\n",
        "file_path2 = '/content/drive/My Drive/P2TF/articles_2.txt'\n",
        "with open(file_path2, 'r', encoding='utf-8') as f: text4 = f.read()[:100000]\n",
        "with open(file_path2, 'r', encoding='utf-8') as f: text5 = f.read()[100000:200000]\n",
        "with open(file_path2, 'r', encoding='utf-8') as f: text6 = f.read()[200000:300469]\n",
        "\n",
        "file_path3 = '/content/drive/My Drive/P2TF/articles_3.txt'\n",
        "with open(file_path3, 'r', encoding='utf-8') as f: text7 = f.read()[:100000]\n",
        "with open(file_path3, 'r', encoding='utf-8') as f: text8 = f.read()[100000:200000]\n",
        "with open(file_path3, 'r', encoding='utf-8') as f: text9 = f.read()[200000:300469]"
      ],
      "metadata": {
        "id": "-Q3KfhXIIp3Q"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сначала попробуем подать в модель тексты разной длины без предобработки\n",
        "texts = [text1, text2, text3, text4, text5, text6, text7, text8, text9]"
      ],
      "metadata": {
        "id": "Ik1FehBDI8ZN"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lables = [1, 1, 1, 1, 1, 1, 0, 0, 0]"
      ],
      "metadata": {
        "id": "NYq5tABFJCaS"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаем объект векторизатора\n",
        "vectorizer = CountVectorizer()"
      ],
      "metadata": {
        "id": "Z3om__bYSx1s"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# векторизуем независимую переменную, т.к. она представлена текстовыми данными\n",
        "X1 = vectorizer.fit_transform(texts)"
      ],
      "metadata": {
        "id": "wz-ikplPId12"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, lables, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Rvm1W4fwIkC3"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение логистической регрессии\n",
        "clf1_cv = LogisticRegression()\n",
        "clf1_cv.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "0TzjzZzPJPV-",
        "outputId": "0659b823-ecea-4707-ee34-f3d056577bfd"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# применяем метод predict обученного классификатора на тестовых данных (уже преобразованных векторизатором)\n",
        "y_pred1_cv = clf1_cv.predict(X_test)"
      ],
      "metadata": {
        "id": "58nXfGoSvWEY"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred1_cv))\n",
        "# Модель отлично справилась с заданием, векторизатор и классификатор выбраны правильно\n",
        "# Также, отметим, что модель отлично работает без предобработки текстов"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e63YNcjnv6gY",
        "outputId": "9dce74b3-4e86-4f6c-8300-9238ebf47fa9"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказываем класс для каждого текста\n",
        "predictions = clf1_cv.predict(X1)\n",
        "for i, text in enumerate(texts):\n",
        "    author = \"Автор\" if predictions[i] == 1 else \"Коллега\"\n",
        "    print(f\"Текст {i+1} имеет авторство: {author}\")\n",
        "# Видим, что модель точно определила корпуса, написанные Автором и Псведонимом, как \"Автор\" и ни разу не спутала Автора с Коллегой"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j00voAvwJmjQ",
        "outputId": "f4d5b517-5f6d-4e7c-a558-231cfb234449"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текст 1 имеет авторство: Автор\n",
            "Текст 2 имеет авторство: Автор\n",
            "Текст 3 имеет авторство: Автор\n",
            "Текст 4 имеет авторство: Автор\n",
            "Текст 5 имеет авторство: Автор\n",
            "Текст 6 имеет авторство: Автор\n",
            "Текст 7 имеет авторство: Коллега\n",
            "Текст 8 имеет авторство: Коллега\n",
            "Текст 9 имеет авторство: Коллега\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# проверим, как справится Tfidf Vectorizer на той же модели логистической регрессии\n",
        "X2 = tfidf_vectorizer.fit_transform(texts)"
      ],
      "metadata": {
        "id": "R-N9EspbUHkf"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделяем данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X2, lables, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "EXa8RKDKVXRG"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучаем классификатор\n",
        "clf1_tf = LogisticRegression()\n",
        "clf1_tf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "-vQB-HBBVfaE",
        "outputId": "07ccc4c2-b560-4938-942b-1bf5a08d5ea1"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# делаем предсказание на тестовой выборке\n",
        "y_pred1_tf = clf1_tf.predict(X_test)"
      ],
      "metadata": {
        "id": "Fr6LlK4rVtFu"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred1_tf))\n",
        "# Видим, что модель вдвое хуже справилась с предсказаниями, не смогла правильно предсказать класс \"Коллега\"\n",
        "# Получается, что Tf-idf - не подходит для данной задачи"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYFKBHW-VtB8",
        "outputId": "0420ef9b-e111-45c3-ac54-844249c99d00"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказываем класс для каждого текста\n",
        "predictions = clf1_tf.predict(X2)\n",
        "for i, text in enumerate(texts):\n",
        "    author = \"Автор\" if predictions[i] == 1 else \"Коллега\"\n",
        "    print(f\"Текст {i+1} имеет авторство: {author}\")\n",
        "# Модель не смогла правильно предсказать класс \"Коллега\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y04rBlYifgvu",
        "outputId": "383480a5-2966-479d-c612-0e9ed751d33e"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текст 1 имеет авторство: Автор\n",
            "Текст 2 имеет авторство: Автор\n",
            "Текст 3 имеет авторство: Автор\n",
            "Текст 4 имеет авторство: Автор\n",
            "Текст 5 имеет авторство: Автор\n",
            "Текст 6 имеет авторство: Автор\n",
            "Текст 7 имеет авторство: Автор\n",
            "Текст 8 имеет авторство: Автор\n",
            "Текст 9 имеет авторство: Автор\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Модель для классификации текстов на два класса (автор или коллега) на основе мультиномиального классификатора."
      ],
      "metadata": {
        "id": "rO4ZB_zSPPH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "id": "R_WqKk8LQjmh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X3 = vectorizer.fit_transform(texts)"
      ],
      "metadata": {
        "id": "NszEeLhPRqXV"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X3, lables, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "dVzF_yo8SJ4r"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучаем классификатор\n",
        "clf2_cv = MultinomialNB()\n",
        "clf2_cv.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "QKKmIRvgSRC2",
        "outputId": "461b074f-ccaf-47bf-d72b-80b1858ef165"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказываем авторов для тестового набора\n",
        "y_pred2_cv = clf2_cv.predict(X_test)"
      ],
      "metadata": {
        "id": "vdG_UF6mSWL4"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred2_cv))\n",
        "# Видим, что модель работает также хорошо, как и в случае с логистической регрессией, значит, выбран верный классификатор и векторизатор"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZzBp3ZIbCTR",
        "outputId": "2ff65384-0b63-4d3c-b10d-89dd865cfb2b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказываем класс для каждого текста\n",
        "predictions = clf2_cv.predict(X3)\n",
        "for i, text in enumerate(texts):\n",
        "    author = \"Автор\" if predictions[i] == 1 else \"Коллега\"\n",
        "    print(f\"Текст {i+1} имеет авторство: {author}\")\n",
        "# Видим, что модель точно определила корпуса, написанные Автором и Псведонимом, как \"Автор\" и ни разу не спутала Автора с Коллегой"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3K5QFtxScGF",
        "outputId": "6829e4e0-b23f-4ddd-ee53-2c6d6269cbd4"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текст 1 имеет авторство: Автор\n",
            "Текст 2 имеет авторство: Автор\n",
            "Текст 3 имеет авторство: Автор\n",
            "Текст 4 имеет авторство: Автор\n",
            "Текст 5 имеет авторство: Автор\n",
            "Текст 6 имеет авторство: Автор\n",
            "Текст 7 имеет авторство: Коллега\n",
            "Текст 8 имеет авторство: Коллега\n",
            "Текст 9 имеет авторство: Коллега\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# проверим, как справится Tfidf Vectorizer на этой же модели мультиномиальной классификации\n",
        "X4 = tfidf_vectorizer.fit_transform(texts)"
      ],
      "metadata": {
        "id": "lcUWpGQecnlj"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X4, lables, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "R_pBB-MldDtD"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf2_tf = MultinomialNB()\n",
        "clf2_tf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "nYiLmCFpdcFO",
        "outputId": "8d4222ac-27c1-4668-ed55-49a7ec75f55c"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказываем авторов для тестового набора\n",
        "y_pred2_tf = clf2_tf.predict(X_test)"
      ],
      "metadata": {
        "id": "e4JNmQiWm7EO"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred2_tf))\n",
        "# Результат аналогичный другому неудачному результату выше - применение  tfidf ухудшает качество работы моделей\n",
        "# применение опции stratify (stratify = lables) выдало такой же результат"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhWuTZZHnHra",
        "outputId": "03bed1aa-41f8-4693-946b-79f858398d15"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказываем класс для каждого текста\n",
        "predictions = clf2_tf.predict(X4)\n",
        "for i, text in enumerate(texts):\n",
        "    author = \"Автор\" if predictions[i] == 1 else \"Коллега\"\n",
        "    print(f\"Текст {i+1} имеет авторство: {author}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR8lgjpwvYdD",
        "outputId": "bfc6e869-fc6f-4cb1-a69d-b58abeb44a52"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текст 1 имеет авторство: Автор\n",
            "Текст 2 имеет авторство: Автор\n",
            "Текст 3 имеет авторство: Автор\n",
            "Текст 4 имеет авторство: Автор\n",
            "Текст 5 имеет авторство: Автор\n",
            "Текст 6 имеет авторство: Автор\n",
            "Текст 7 имеет авторство: Автор\n",
            "Текст 8 имеет авторство: Автор\n",
            "Текст 9 имеет авторство: Автор\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.3 Модель для классификации текстов на два класса (автор или коллега) на основе классификатора \"Рандомный Лес\" с подбором гиперпараметров."
      ],
      "metadata": {
        "id": "cVcMRs_DfzKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "Y62gET_BftCR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтобы у модели было больше примеров каждого класса, разобьем каждый текст на три части\n",
        "# Также, я пробовала подавать тексты как сокращенными до одной длины, так и полной длины, но результаты по качеству в итоге были одинаковыми\n",
        "file_path1 = '/content/drive/My Drive/P2TF/articles_1.txt'\n",
        "with open(file_path1, 'r', encoding='utf-8') as f: text1 = f.read()[:100000]\n",
        "with open(file_path1, 'r', encoding='utf-8') as f: text2 = f.read()[100000:200000]\n",
        "with open(file_path1, 'r', encoding='utf-8') as f: text3 = f.read()[200000:]\n",
        "\n",
        "file_path2 = '/content/drive/My Drive/P2TF/articles_2.txt'\n",
        "with open(file_path2, 'r', encoding='utf-8') as f: text4 = f.read()[:100000]\n",
        "with open(file_path2, 'r', encoding='utf-8') as f: text5 = f.read()[100000:200000]\n",
        "with open(file_path2, 'r', encoding='utf-8') as f: text6 = f.read()[200000:300469]\n",
        "\n",
        "file_path3 = '/content/drive/My Drive/P2TF/articles_3.txt'\n",
        "with open(file_path3, 'r', encoding='utf-8') as f: text7 = f.read()[:100000]\n",
        "with open(file_path3, 'r', encoding='utf-8') as f: text8 = f.read()[100000:200000]\n",
        "with open(file_path3, 'r', encoding='utf-8') as f: text9 = f.read()[200000:300469]\n",
        "\n"
      ],
      "metadata": {
        "id": "hMNUP4G_ghAF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Тексты подавались как предобработанными, так и нет, но результаты по качеству в итоге были одинаковыми\n",
        "def clean_text(text):\n",
        "    text_lemmatized = mystem.lemmatize(text)\n",
        "    text_without_punkt_lem = [word.lower() for word in text_lemmatized if word.isalpha()] # and word not in stopwords.words('russian')]\n",
        "    return ' '.join(text_without_punkt_lem)"
      ],
      "metadata": {
        "id": "u-MdlVE_5lrR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    clean_text(text1),\n",
        "    clean_text(text2),\n",
        "    clean_text(text3),\n",
        "    clean_text(text4),\n",
        "    clean_text(text5),\n",
        "    clean_text(text6),\n",
        "    clean_text(text7),\n",
        "    clean_text(text8),\n",
        "    clean_text(text9)\n",
        " ]"
      ],
      "metadata": {
        "id": "zZBis_8e6oHt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# попробуем подать в модель тексты без предобработки\n",
        "# texts = [text1, text2, text3, text4, text5, text6, text7, text8, text9]"
      ],
      "metadata": {
        "id": "q2sTJFth5rED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors = [1, 1, 1, 1, 1, 1, 0, 0, 0]"
      ],
      "metadata": {
        "id": "d0SJ_MZY5t_Y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# векторизуем тексты\n",
        "#X_rf = tfidf_vectorizer.fit_transform(texts)\n",
        "\n",
        "#vectorizer = CountVectorizer()\n",
        "X_rf = vectorizer.fit_transform(texts)\n",
        "\n",
        "# пробовались разные варианты с применением Count Vectorizer и с Tf-idf Vectorizer, но результаты оценки качества не менялись"
      ],
      "metadata": {
        "id": "y_LKS4a7hKO9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# разделяем данные на тренировочную и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rf, authors, test_size=0.2, random_state=42)\n",
        "# в нескольких комбинациях с применением разной длины текстов, предобработки и векторизаторов я также пробовала добавить stratify = authors,\n",
        "# т.к. текстов Коллеги в два раза меньше, чем текстов Автора, но на результаты оценки качества это не повлияло"
      ],
      "metadata": {
        "id": "u9jDbyUxgXFz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подбор параметров для модели с помощью Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_features': [0.3, 'sqrt', 1.0],\n",
        "    'max_depth': [None, 5, 7, 10, 20, 30]\n",
        "}"
      ],
      "metadata": {
        "id": "7k4gxCi4h2FF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rf = RandomForestClassifier()\n",
        "grid_search = GridSearchCV(Rf, param_grid, cv=2) # также пробовала и cv = 5, результаты не менялись, при этом модель предупреждала, что\n",
        "#\"The least populated class in y has only 2 members, which is less than n_splits=5\"\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "QnPz-Cwlk1UQ",
        "outputId": "d414cd09-7ea0-48ca-9b8a-4d936a6045b8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, estimator=RandomForestClassifier(),\n",
              "             param_grid={'max_depth': [None, 5, 7, 10, 20, 30],\n",
              "                         'max_features': [0.3, 'sqrt', 1.0],\n",
              "                         'n_estimators': [50, 100, 150]})"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=RandomForestClassifier(),\n",
              "             param_grid={&#x27;max_depth&#x27;: [None, 5, 7, 10, 20, 30],\n",
              "                         &#x27;max_features&#x27;: [0.3, &#x27;sqrt&#x27;, 1.0],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 150]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2, estimator=RandomForestClassifier(),\n",
              "             param_grid={&#x27;max_depth&#x27;: [None, 5, 7, 10, 20, 30],\n",
              "                         &#x27;max_features&#x27;: [0.3, &#x27;sqrt&#x27;, 1.0],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 150]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение лучших параметров\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "# этот результат сохранялся и при применении предобработки, и без нее, и с разными векторизаторами, и со/без стратификацией(-ии), и при cv =5, и при cv = 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW1qOzKVoR7U",
        "outputId": "6f115e32-5a4c-402e-9e23-04056fed732e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'max_features': 0.3, 'n_estimators': 50}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели с лучшими параметрами\n",
        "best_clf = RandomForestClassifier(**best_params)\n",
        "best_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "IwHFaauPpAO3",
        "outputId": "953ffee5-df7e-4092-9a4c-496312cf38f5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_features=0.3, n_estimators=50)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_features=0.3, n_estimators=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=0.3, n_estimators=50)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказание авторства текстов\n",
        "y_rf_pred = best_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "WISnMxskpOpj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_rf_pred))\n",
        "# Этот результат выходил во всех вариациях с использованием данной классификации"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWW5ToqDqdQx",
        "outputId": "a8373c1e-7ff4-4221-ce7f-ba2ef9e98f00"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Глубокое обучение, Doc2Vec, TSNE"
      ],
      "metadata": {
        "id": "L7uVBU5LSNRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Эмбединги текстов и вычисление семантической близости с применением Doc2Vec"
      ],
      "metadata": {
        "id": "u44boUr2iH1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "f58p7ISToW91"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path1 = '/content/drive/My Drive/P2TF/articles_1.txt'\n",
        "with open(file_path1, 'r', encoding='utf-8') as f: text1 = f.read()\n",
        "\n",
        "file_path2 = '/content/drive/My Drive/P2TF/articles_2.txt'\n",
        "with open(file_path2, 'r', encoding='utf-8') as f: text2 = f.read()[:300469]\n",
        "\n",
        "file_path3 = '/content/drive/My Drive/P2TF/articles_3.txt'\n",
        "with open(file_path3, 'r', encoding='utf-8') as f: text3 = f.read()[:300469]"
      ],
      "metadata": {
        "id": "GiKv7H1ST5fj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors = []\n",
        "\n",
        "file_path1 = '/content/drive/My Drive/P2TF/articles_1.txt'\n",
        "with open(file_path1, 'r', encoding='utf-8') as f: authors.append(\"Автор\")\n",
        "\n",
        "file_path3 = '/content/drive/My Drive/P2TF/articles_3.txt'\n",
        "with open(file_path3, 'r', encoding='utf-8') as f: authors.append(\"Коллега\")\n",
        "\n",
        "print(authors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfSJ7TIUWXdc",
        "outputId": "e84fe932-7d4c-41ff-d69c-5f4bab05ccb2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Автор', 'Коллега']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# предобрабатываем тексты - лемматизируем, удаляем знаки препинания, токенизируем; стоп-слова оставляем\n",
        "def clean_text(text):\n",
        "    text_lemmatized = mystem.lemmatize(text)\n",
        "    text_without_punkt_lem = [word.lower() for word in text_lemmatized if word.isalpha()]\n",
        "    text_list_without_punkt_lem = ' '.join(text_without_punkt_lem)\n",
        "    tokens = word_tokenize(text_list_without_punkt_lem)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "o4PqJBWCUatK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_dv = [\n",
        "    clean_text(text1),\n",
        "    clean_text(text3)\n",
        "]"
      ],
      "metadata": {
        "id": "rMyVxbjUnDes"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем тэги в наши текстовые данные для последующей подачи в модель\n",
        "docs = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts_dv)]"
      ],
      "metadata": {
        "id": "cVgz4QgeseWR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# обучаем модель\n",
        "d2v_model = Doc2Vec(vector_size=100, window=2, min_count=1, workers=4, epochs=150)"
      ],
      "metadata": {
        "id": "b5xqJ7fIxh73"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаём словарь модели на основе корпуса документов\n",
        "d2v_model.build_vocab(docs)"
      ],
      "metadata": {
        "id": "34RAYBWeviqC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "d2v_model.train(docs, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GocMHKJB10kY",
        "outputId": "c9ed394e-3ee0-4df0-da4a-2a0fa1868479"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8.46 s, sys: 131 ms, total: 8.59 s\n",
            "Wall time: 7.94 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# предобрабатываем корпус под псевдонимом\n",
        "text2_doc = (clean_text(text2))"
      ],
      "metadata": {
        "id": "IbnoWEU_QLvi"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# получаем вектор корпуса под псевдонимом\n",
        "text2_vector = d2v_model.infer_vector(text2_doc)"
      ],
      "metadata": {
        "id": "RrB_IbsMQ4DC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# получаем косинусное сходство векторов Автора [0] и Коллеги [1] с вектором клрпуса под псевдонимом\n",
        "similarity = d2v_model.dv.most_similar([text2_vector], topn=2)"
      ],
      "metadata": {
        "id": "faDivhVYR5Qe"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity\n",
        "# результат сходства в паре Автор-Псевдоним (0.67) очень близок к результату этой же пары в пункте про векторное сходство (0.66)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIMHtxDTE9JS",
        "outputId": "d4acbb8d-83b5-4d1b-eb1c-158282b9ff73"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.6756372451782227), (1, 0.6425831317901611)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Журналист, к которому корпус под псевдонимом ближе всего: {similarity[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJkE2VSsEM3s",
        "outputId": "1901a902-b5b0-47b1-ae2a-34a53d35d5dd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Журналист, к которому корпус под псевдонимом ближе всего: (0, 0.6756372451782227)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "authors[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "U_5QHWX8aNZz",
        "outputId": "92c4dce6-5169-4a65-fb97-166dd3a9978e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Автор'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ранжируем корпуса по степени косинусного сходства с копусом под певдонимом\n",
        "for doc_id, sim in d2v_model.dv.most_similar([text2_vector], topn=2):\n",
        "  print(authors[doc_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0X5TXHSamG2",
        "outputId": "9f0a9028-7b3c-478d-f43e-5bffd9beb062"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Автор\n",
            "Коллега\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Визуализация c применением TSNE"
      ],
      "metadata": {
        "id": "PliEZRAM-0Bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts_author = []\n",
        "texts_penname = []\n",
        "texts_colleague = []"
      ],
      "metadata": {
        "id": "JLwm0t9pX3Gx"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# читаем каждый файл (уже предобработанный) и разбиваем его на десять частей, добавляя каждую из них в соответствующий список и присваиваем тэги каждой из частей:\n",
        "file_path1 = '/content/drive/My Drive/P2TF/articles1_nltk.txt'\n",
        "with open(file_path1, 'r', encoding='utf-8') as f: text1 = f.read().split(' ')\n",
        "chunk_size = len(text1) // 20\n",
        "texts_author.extend([TaggedDocument(words=text1[i:i+chunk_size], tags=[f\"Author_{j}\"]) for j, i in enumerate (range(0, len(text1), chunk_size))])\n",
        "\n",
        "file_path2 = '/content/drive/My Drive/P2TF/articles2_short_nltk.txt'\n",
        "with open(file_path2, 'r', encoding='utf-8') as f: text2 = f.read()[:40533].split(' ')\n",
        "chunk_size = len(text2) // 20\n",
        "texts_penname.extend([TaggedDocument(words=text2[i:i+chunk_size], tags=[f\"Penname_{j}\"]) for j, i in enumerate (range(0, len(text2), chunk_size))])\n",
        "\n",
        "file_path3 = '/content/drive/My Drive/P2TF/articles3_short_nltk.txt'\n",
        "with open(file_path3, 'r', encoding='utf-8') as f: text3 = f.read()[:40533].split(' ')\n",
        "chunk_size = len(text3) // 20\n",
        "texts_colleague.extend([TaggedDocument(words=text3[i:i+chunk_size], tags=[f\"Colleague_{j}\"]) for j, i in enumerate (range(0, len(text3), chunk_size))])"
      ],
      "metadata": {
        "id": "3rhxSBsofnxj"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PUyVDRCd_nU",
        "outputId": "d87950d3-6b3c-46ee-d528-db89fcbc3ee4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40533"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cоздаем и обучаем модель Doc2Vec\n",
        "docs_tsne = texts_author + texts_penname + texts_colleague\n",
        "d2v_model_tsne = Doc2Vec(docs_tsne, vector_size=100, window=2, min_count=1, workers=4,epochs=150)"
      ],
      "metadata": {
        "id": "SeE4PZ0aX2nR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение векторов документов и авторов\n",
        "vectors_tsne = [d2v_model_tsne.dv[tag] for tag in d2v_model_tsne.dv.index_to_key]\n",
        "vectors_tsne= np.array(vectors_tsne)"
      ],
      "metadata": {
        "id": "YAeQ-dWMBnjF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# снижаем размерность\n",
        "tsne = TSNE(n_components=2, perplexity=20, random_state=42)\n",
        "vectors_2d = tsne.fit_transform(vectors_tsne)"
      ],
      "metadata": {
        "id": "8iCUUZerx27c"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# строим график\n",
        "plt.figure(figsize=(10, 6))\n",
        "colors = {'Author': 'red', 'Penname': 'blue', 'Colleague': 'green'}\n",
        "markers = {'Author': 'o', 'Penname': 's', 'Colleague': 'D'}\n",
        "\n",
        "for i, txt in enumerate(d2v_model_tsne.dv.index_to_key):\n",
        "    author, num = txt.split('_')\n",
        "    plt.scatter (vectors_2d[i, 0], vectors_2d[i, 1], c=colors[author], marker=markers[author], label=author)\n",
        "\n",
        "handles, labels = plt.gca().get_legend_handles_labels()\n",
        "by_label = dict(zip(labels, handles))\n",
        "plt.legend(by_label.values(), by_label.keys(), loc='upper left', bbox_to_anchor=(1, 1))\n",
        "plt.title('Текстовые кластеры для атрибуции авторства',\n",
        "          size=18,\n",
        "          loc='left',\n",
        "          pad=10)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "435fca50-ff23-44ed-ef7e-0f470b825355",
        "id": "8sQ5yL2-PMUV"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}